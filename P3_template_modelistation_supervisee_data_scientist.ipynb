{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè¢ Projet 3 : Project Lead Douglas Pr√©diction de la Consommation √ânerg√©tique et des √âmissions CO2\n",
    "\n",
    "## üéØ Objectifs du Projet\n",
    "\n",
    "Ce projet vise √† construire **deux mod√®les de r√©gression supervis√©e** pour pr√©dire :\n",
    "\n",
    "1. **La consommation √©nerg√©tique** (`SiteEnergyUse(kBtu)`) des b√¢timents non-r√©sidentiels de Seattle\n",
    "2. **Les √©missions de CO2** (`TotalGHGEmissions`) associ√©es √† ces b√¢timents\n",
    "\n",
    "**Contexte :** Dataset \"2016 Building Energy Benchmarking\" de la ville de Seattle (3376 b√¢timents initiaux).\n",
    "\n",
    "**M√©thodologie :** Analyse exploratoire ‚Üí Feature Engineering ‚Üí Mod√©lisation ‚Üí Optimisation ‚Üí Interpr√©tation\n",
    "\n",
    "---\n",
    "\n",
    "# üìä PARTIE 0 : Analyse Exploratoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Exploratoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset\n",
    "df = pd.read_csv(\"data/2016_Building_Energy_Benchmarking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde comment les batiments sont d√©finis dans le dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde le nombre de valeurs manquantes par colonne ainsi que leur type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche le pourcentage de valeurs manquantes par colonne.\n",
    "print(df.isna().mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìñ Compr√©hension des colonnes principales\n",
    "\n",
    "**Variables cibles potentielles (consommation √©nerg√©tique) :**\n",
    "\n",
    "- `SiteEnergyUse(kBtu)` : Consommation totale d'√©nergie sur site\n",
    "- `TotalGHGEmissions` : √âmissions totales de gaz √† effet de serre\n",
    "\n",
    "| Type de Feature  | Question pos√©e         | R√¥le                                                      | Impact sur la Pr√©diction                                                                                           |\n",
    "| :--------------- | :--------------------- | :-------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |\n",
    "| **Identitaire**  | _C'est qui ?_          | Sert √† identifier, filtrer ou grouper les donn√©es.        | **Faible**<br>Le nom du b√¢timent ne change pas sa physique.                                                        |\n",
    "| **Structurelle** | _C'est fait comment ?_ | Caract√©ristiques physiques immuables (Le Contenant).      | **Physique**<br>D√©termine la consommation de base (Plus c'est grand/vieux, plus √ßa consomme).                      |\n",
    "| **Usage**        | _On y fait quoi ?_     | Le comportement et l'activit√© √† l'int√©rieur (Le Contenu). | **Intensit√©**<br>Variable critique : explique pourquoi un H√¥pital consomme 10x plus qu'un Entrep√¥t de m√™me taille. |\n",
    "\n",
    "**Features identitaires :**\n",
    "\n",
    "- `PropertyName` : Nom du b√¢timent (identification)\n",
    "- `BuildingType` : Type de b√¢timent (r√©sidentiel/non-r√©sidentiel) ‚Üí **Filtre principal**\n",
    "- `PrimaryPropertyType` : Cat√©gorie d√©taill√©e (Office, School, Warehouse, etc.)\n",
    "\n",
    "**Features structurelles :**\n",
    "\n",
    "- `PropertyGFATotal` : Surface totale en pieds carr√©s (crucial pour normalisation)\n",
    "- `YearBuilt` : Ann√©e de construction (√¢ge du b√¢timent)\n",
    "- `NumberofBuildings` : Nombre de b√¢timents dans la propri√©t√©\n",
    "\n",
    "**Features d'usage :**\n",
    "\n",
    "- `LargestPropertyUseType` : Usage principal du b√¢timent\n",
    "- `SecondLargestPropertyUseType` : Usage secondaire (si pr√©sent)\n",
    "- `LargestPropertyUseTypeGFA` : Surface d√©di√©e √† l'usage principal\n",
    "\n",
    "**Strat√©gie de nettoyage :**\n",
    "\n",
    "1. Garder les colonnes avec **<50% de valeurs manquantes** ET pertinentes pour la mod√©lisation\n",
    "2. Supprimer les colonnes **constantes** (ou redondante)\n",
    "3. √âliminer les lignes avec **valeurs manquantes sur les targets**\n",
    "4. D√©tecter et retirer les **incoh√©rences m√©tier** (surface/√©nergie n√©gatives ou nulles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parations des chiffres\n",
    "n_total = df.shape[0]\n",
    "nb_habitations = df[\"BuildingType\"].str.contains(\"Multifamily\").sum()\n",
    "\n",
    "# On calcule le pourcentage dans une variable √† part\n",
    "pct_habitations = nb_habitations / n_total\n",
    "\n",
    "print(f\"Nombre initial de b√¢timents : {n_total}\")\n",
    "print(\n",
    "    f\"   - Dont habitations (Hors p√©rim√®tre) : {nb_habitations} ({pct_habitations:.1%})\"  # Arrondir et faire x100 + le symbole \"%\"\n",
    ")\n",
    "\n",
    "# Filtre qui permet de ne garder que les b√¢timents non r√©sidentiels\n",
    "df = df[~df[\"BuildingType\"].str.contains(\"Multifamily\")]  # (~ = NOT)\n",
    "n_after_filter = df.shape[0]\n",
    "\n",
    "print(f\"Nombre de b√¢timents apr√®s filtre 'Non-Res' : {n_after_filter}\")\n",
    "\n",
    "\n",
    "# Liste des colonnes identifi√©es comme inutilisables (>50% vide ou hors sujet => risque de bruit)\n",
    "cols_to_drop = [\n",
    "    \"Comments\",\n",
    "    \"Outlier\",\n",
    "    \"YearsENERGYSTARCertified\",\n",
    "]\n",
    "\n",
    "\n",
    "# Nettoyage structurel du dataset\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Suppression des rows o√π les cibles sont vides (0 vide dans notre cas donc parfait)\n",
    "targets = [\"SiteEnergyUse(kBtu)\", \"TotalGHGEmissions\"]\n",
    "df = df.dropna(subset=targets)\n",
    "\n",
    "# V√©rification  de la taille\n",
    "print(\n",
    "    f\"Taille du dataset apr√®s nettoyage structurel : {df.shape}\"  # (Nombre de lignes et colonnes )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE DES COLONNES\n",
    "\n",
    "# Les colonnes qui n'ont qu'une seule valeur unique\n",
    "const_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "print(f\"Colonnes constantes supprim√©es : {const_cols}\")\n",
    "df = df.drop(columns=const_cols)\n",
    "\n",
    "# DOUBLONS\n",
    "duplicates_count = df.duplicated().sum()\n",
    "print(f\"Nombre de doublons trouv√©s : {duplicates_count}\")\n",
    "\n",
    "# Si doublons on supprime pour garder qu'une seule version unique\n",
    "if duplicates_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Doublons supprim√©s.\")\n",
    "\n",
    "# INCOH√âRENCES\n",
    "# Garder que les valeurs positives\n",
    "nb_incoherent = len(\n",
    "    df[(df[\"PropertyGFATotal\"] <= 0) | (df[\"SiteEnergyUse(kBtu)\"] <= 0)]\n",
    ")\n",
    "if nb_incoherent > 0:\n",
    "    print(\n",
    "        f\"\\nSuppression de {nb_incoherent} b√¢timents incoh√©rents (Surface ou Energie <= 0).\"\n",
    "    )\n",
    "    df = df[df[\"PropertyGFATotal\"] > 0]\n",
    "    df = df[df[\"SiteEnergyUse(kBtu)\"] > 0]\n",
    "\n",
    "\n",
    "# GESTION DES NaN POUR VARIABLES D'USAGE\n",
    "# NaN dans Third* = \"pas de 3√®me usage\" ‚Üí Information utile, pas une erreurprint(f\"\\n---> Dataset pr√™t pour la suite : {df.shape}\")\n",
    "\n",
    "df[\"ThirdLargestPropertyUseType\"] = df[\"ThirdLargestPropertyUseType\"].fillna(\"None\")\n",
    "df[\"ThirdLargestPropertyUseTypeGFA\"] = df[\"ThirdLargestPropertyUseTypeGFA\"].fillna(0)\n",
    "print(\"   ThirdLargestPropertyUseType : NaN ‚Üí 'None' (absence de 3√®me usage)\")\n",
    "print(\"   ThirdLargestPropertyUseTypeGFA : NaN ‚Üí 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Statistique Descriptive\n",
    "\n",
    "| Indicateur Statistique | D√©finition Simple                                                 | Interpr√©tation pour le Projet (Seattle)                                                                                                  |\n",
    "| :--------------------- | :---------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Moyenne** (`mean`)   | Le centre de gravit√© math√©matique.                                | **Tendance globale**, mais fortement tir√©e vers le haut par les quelques b√¢timents g√©ants (Campus, H√¥pitaux).                            |\n",
    "| **M√©diane** (`median`) | La valeur centrale (50% au-dessus, 50% en dessous).               | **Le b√¢timent \"Standard\"**. C'est la valeur la plus repr√©sentative de la r√©alit√© de la majorit√© du parc immobilier.                      |\n",
    "| **√âcart-type** (`std`) | La dispersion des valeurs autour de la moyenne.                   | **La diversit√©**. Un √©cart-type √©lev√© indique que le parc est tr√®s h√©t√©rog√®ne (m√©lange de petits commerces et de grands buildings).      |\n",
    "| **Outliers** (`3œÉ`)    | Valeurs d√©passant le seuil statistique (Moyenne + 3x √âcart-type). | **Les anomalies ou g√©ants**. Ce sont les cas extr√™mes (structures tr√®s √©nergivores) qu'il faudra peut-√™tre traiter √† part ou surveiller. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques sur la consommation d'√©nergie\n",
    "print(\"\\nüîã CONSOMMATION D'√âNERGIE (kBtu)\")\n",
    "print(f\"   Moyenne : {df['SiteEnergyUse(kBtu)'].mean():,.0f} kBtu\")\n",
    "print(f\"   M√©diane : {df['SiteEnergyUse(kBtu)'].median():,.0f} kBtu\")\n",
    "print(f\"   √âcart-type : {df['SiteEnergyUse(kBtu)'].std():,.0f} kBtu\")\n",
    "print(f\"   Min : {df['SiteEnergyUse(kBtu)'].min():,.0f} kBtu\")\n",
    "print(f\"   Max : {df['SiteEnergyUse(kBtu)'].max():,.0f} kBtu\")\n",
    "\n",
    "# Statistiques sur les √©missions CO2\n",
    "print(\"\\nüåç √âMISSIONS DE CO2 (Metric Tons)\")\n",
    "print(f\"   Moyenne : {df['TotalGHGEmissions'].mean():,.0f} tons\")\n",
    "print(f\"   M√©diane : {df['TotalGHGEmissions'].median():,.0f} tons\")\n",
    "print(f\"   √âcart-type : {df['TotalGHGEmissions'].std():,.0f} tons\")\n",
    "print(f\"   Min : {df['TotalGHGEmissions'].min():,.0f} tons\")\n",
    "print(f\"   Max : {df['TotalGHGEmissions'].max():,.0f} tons\")\n",
    "\n",
    "# D√©tection des outliers\n",
    "energy_mean = df[\"SiteEnergyUse(kBtu)\"].mean()\n",
    "energy_std = df[\"SiteEnergyUse(kBtu)\"].std()\n",
    "outliers_energy = df[df[\"SiteEnergyUse(kBtu)\"] > energy_mean + 3 * energy_std]\n",
    "\n",
    "print(\"\\nOUTLIERS D√âTECT√âS :\")\n",
    "print(\n",
    "    f\"B√¢timents avec consommation > 3œÉ : {len(outliers_energy)} ({len(outliers_energy) / len(df) * 100:.1f}%)\"\n",
    "    # 3œÉ (Sigma) = 3 fois l'√©cart-type : c'est la fronti√®re statistique au-del√† de laquelle une valeur est consid√©r√©e comme une anomalie (Outlier).\n",
    ")\n",
    "print(\n",
    "    f\"Seuil outlier : {energy_mean + 3 * energy_std:,.0f} kBtu\"\n",
    ")  # on d√©termine ce seuil en fonction de la distribution des donn√©es(moyenne et √©cart-type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Graphiques 1 & 2 : Classement √ânerg√©tique et √âcologique par Type de B√¢timent\n",
    "\n",
    "**Objectif :** Comparer les 22 types de b√¢timents pour identifier les cat√©gories les plus consommatrices et polluantes.\n",
    "\n",
    "**M√©thodologie technique :**\n",
    "\n",
    "- **Visualisation** : Boxplots (bo√Ætes √† moustaches) pour visualiser m√©diane, quartiles et outliers\n",
    "- **Tri intelligent** : Classement automatique par m√©diane croissante (les plus √©conomes √† gauche, les plus gourmands √† droite)\n",
    "- **√âchelle logarithmique** : Permet de comparer sur un m√™me graphique les entrep√¥ts (~100k kBtu) et les h√¥pitaux (~100M kBtu)\n",
    "- **Dataset complet** : Analyse sur les 1650 b√¢timents (tous types confondus)\n",
    "\n",
    "**Graphique 1 : Classement de la Consommation d'√ânergie**\n",
    "\n",
    "- Lecture imm√©diate des types les plus √©nergivores (positionn√©s √† droite)\n",
    "- Hauteur de chaque bo√Æte = variabilit√© au sein d'une cat√©gorie\n",
    "- Points isol√©s = outliers (b√¢timents atypiques)\n",
    "\n",
    "**Graphique 2 : Classement des √âmissions de CO2**\n",
    "\n",
    "- M√™me m√©thodologie appliqu√©e aux √©missions de gaz √† effet de serre\n",
    "- Permet de v√©rifier la corr√©lation entre consommation √©nerg√©tique et pollution\n",
    "- Confirme que les types les plus √©nergivores sont g√©n√©ralement les plus pollueurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consommation d'√ânergie\n",
    "fig_energy = px.box(\n",
    "    df,\n",
    "    x=\"PrimaryPropertyType\",\n",
    "    y=\"SiteEnergyUse(kBtu)\",\n",
    "    color=\"PrimaryPropertyType\",\n",
    "    title=\"Classement de la consommation par type de b√¢timent\",\n",
    "    log_y=True,\n",
    "    points=\"outliers\",\n",
    "    hover_data=[\"PropertyName\"],\n",
    ")\n",
    "\n",
    "# On trie l'axe X par ordre croissant de consommation (m√©diane)\n",
    "# Permet de voir imm√©diatement qui sont les \"mauvais √©l√®ves\" √† droite\n",
    "fig_energy.update_xaxes(categoryorder=\"median ascending\")\n",
    "\n",
    "# On cache la l√©gende qui prend trop de place\n",
    "fig_energy.update_layout(showlegend=False)\n",
    "\n",
    "fig_energy.show()\n",
    "\n",
    "# √âmissions de CO2\n",
    "fig_co2 = px.box(\n",
    "    df,\n",
    "    x=\"PrimaryPropertyType\",\n",
    "    y=\"TotalGHGEmissions\",\n",
    "    color=\"PrimaryPropertyType\",\n",
    "    title=\"Classement des √©missions de CO2 par type de b√¢timent\",\n",
    "    log_y=True,\n",
    "    points=\"outliers\",\n",
    "    hover_data=[\"PropertyName\"],\n",
    ")\n",
    "\n",
    "# On trie par pollution m√©diane ( les plus pollueurs √† droite (mauvais √©l√®ves) )\n",
    "fig_co2.update_xaxes(categoryorder=\"median ascending\")\n",
    "fig_co2.update_layout(showlegend=False)\n",
    "\n",
    "fig_co2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Graphique 3 : Relation Surface vs Consommation (Vue Globale)\n",
    "\n",
    "**üéØ Objectif :** V√©rifier la corr√©lation entre la surface et la consommation sur l'ensemble du parc immobilier, et observer la relation avec les √©missions CO2.\n",
    "\n",
    "**Ce qu'on observe :**\n",
    "\n",
    "- **Corr√©lation forte (Ligne Rouge) :** La ligne de tendance (R√©gression OLS) confirme math√©matiquement que la consommation augmente avec la surface. L'hypoth√®se est valid√©e.\n",
    "- **√âchelle Logarithmique :** Indispensable pour visualiser lisiblement les petits b√¢timents (10k ft¬≤) et les campus g√©ants (5M+ ft¬≤) sur le m√™me plan.\n",
    "- **Indicateur CO2 (Couleur des points) :** La couleur indique le niveau d'√©missions de gaz √† effet de serre. On confirme que les b√¢timents les plus consommateurs sont aussi les plus pollueurs (corr√©lation +0.860).\n",
    "\n",
    "**Points d'attention (Analyse des Outliers) :**\n",
    "\n",
    "- **La \"Normalit√©\" :** La grande majorit√© des points se concentrent autour de la ligne rouge. C'est le comportement attendu.\n",
    "- **Les Anomalies (Outliers) :**\n",
    "  - **Au-dessus de la ligne rouge :** B√¢timents √©nergivores. Pour une m√™me surface, ils consomment beaucoup plus que la moyenne (ex: Laboratoires, Supermarch√©s, ou mauvaise isolation).\n",
    "  - **En-dessous de la ligne rouge :** B√¢timents √©conomes ou √† faible occupation (ex: Entrep√¥ts, Lieux de culte).\n",
    "\n",
    "**üí° Conclusion :** La surface est le facteur d√©terminant principal pour les deux targets (√©nergie ET CO2), mais les √©carts importants autour de la ligne de tendance montrent que le _Type d'usage_ jouera un r√¥le cl√© pour affiner les pr√©dictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = px.scatter(\n",
    "    df,\n",
    "    x=\"PropertyGFATotal\",\n",
    "    y=\"SiteEnergyUse(kBtu)\",\n",
    "    color=\"TotalGHGEmissions\",\n",
    "    opacity=0.5,\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    title=\"Corr√©lation Globale : Surface vs Consommation (+ Tendance)\",\n",
    "    trendline=\"ols\",  # Ajout de la ligne de r√©gression\n",
    "    trendline_color_override=\"red\",\n",
    "    hover_data=[\"PropertyName\", \"PrimaryPropertyType\"],\n",
    ")\n",
    "\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Graphique 4 : Matrice de Corr√©lation (Heatmap)\n",
    "\n",
    "**üéØ Objectif :** Visualiser d'un seul coup d'≈ìil toutes les relations entre les variables num√©riques cl√©s du dataset.\n",
    "\n",
    "**M√©thodologie :**\n",
    "\n",
    "- **Variables s√©lectionn√©es** : Cibles √©nerg√©tiques, caract√©ristiques structurelles et performances\n",
    "- **Coefficient de Pearson** : Mesure la force et le sens de la relation lin√©aire entre deux variables (-1 √† +1)\n",
    "- **Lecture de la Heatmap** :\n",
    "  - **Rouge fonc√© (proche de +1)** : Corr√©lation positive forte (quand l'une augmente, l'autre aussi)\n",
    "  - **Bleu fonc√© (proche de -1)** : Corr√©lation n√©gative forte (relation inverse)\n",
    "  - **Blanc (proche de 0)** : Pas de corr√©lation lin√©aire\n",
    "\n",
    "**Ce qu'on cherche :**\n",
    "\n",
    "1. **Variables fortement corr√©l√©es aux cibles** (`SiteEnergyUse(kBtu)` ET `TotalGHGEmissions`) ‚Üí Features pr√©dictives puissantes\n",
    "2. **Redondances** : Variables tr√®s corr√©l√©es entre elles ‚Üí Risque de multicolin√©arit√© (√† √©viter en mod√©lisation)\n",
    "3. **Relations inattendues** : D√©couvertes de patterns non √©vidents\n",
    "4. **Comparaison des deux targets** : Identifier si les m√™mes features pr√©disent l'√©nergie ET les √©missions CO2\n",
    "\n",
    "**üí° Utilit√© pour la Mod√©lisation :**\n",
    "\n",
    "- S√©lectionner les features les plus pertinentes pour **chaque target** (√ânergie ET CO2)\n",
    "- √âviter d'inclure des variables redondantes qui n'apportent pas d'information suppl√©mentaire\n",
    "- Comprendre les m√©canismes physiques sous-jacents (ex: Surface ‚Üí √ânergie ‚Üí CO2)\n",
    "- **Comparer les profils pr√©dictifs** des deux targets pour adapter la strat√©gie de mod√©lisation\n",
    "- Valider que les deux targets ont suffisamment de corr√©lations avec les features disponibles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des variables num√©riques pertinentes\n",
    "# On garde les variables structurelles, √©nerg√©tiques et d'usage\n",
    "corr_cols = [\n",
    "    \"SiteEnergyUse(kBtu)\",  # TARGET 1 : Consommation totale\n",
    "    \"TotalGHGEmissions\",  # TARGET 2 : √âmissions CO2\n",
    "    \"PropertyGFATotal\",  # Surface totale (facteur principal)\n",
    "    \"YearBuilt\",  # √Çge du b√¢timent (isolation, efficacit√©)\n",
    "    \"NumberofFloors\",  # Hauteur (peut influencer chauffage/clim)\n",
    "    \"NumberofBuildings\",  # Nombre de b√¢timents dans le complexe\n",
    "    \"LargestPropertyUseTypeGFA\",  # Surface du plus grand usage\n",
    "    \"SecondLargestPropertyUseTypeGFA\",  # Surface du 2√®me plus grand usage\n",
    "    \"ThirdLargestPropertyUseTypeGFA\",  # Surface du 3√®me plus grand usage\n",
    "]\n",
    "\n",
    "# Calcul de la matrice de corr√©lation (Pearson)\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "fig_corr = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=corr_matrix.values,\n",
    "        x=corr_matrix.columns,\n",
    "        y=corr_matrix.columns,\n",
    "        colorscale=\"RdBu_r\",\n",
    "        zmid=0,  # Centre de l'√©chelle √† 0\n",
    "        text=corr_matrix.values.round(2),  # Afficher les valeurs\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title=\"Corr√©lation\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_corr.update_layout(\n",
    "    title=\"Matrice de Corr√©lation des Variables Cl√©s\",\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"\",\n",
    "    width=900,\n",
    "    height=800,\n",
    "    xaxis=dict(tickangle=-45),  # Inclinaison des labels\n",
    ")\n",
    "\n",
    "fig_corr.show()\n",
    "\n",
    "\n",
    "print(\"\\n CORR√âLATIONS AVEC LES DEUX TARGETS POTENTIELLES :\\n\")\n",
    "\n",
    "# Target 1 : Consommation d'√©nergie\n",
    "print(\"‚ö° TARGET 1 : SiteEnergyUse(kBtu) - Consommation √©nerg√©tique\")\n",
    "target1_corr = corr_matrix[\"SiteEnergyUse(kBtu)\"].sort_values(ascending=False)\n",
    "for var, corr_value in target1_corr.items():\n",
    "    if var != \"SiteEnergyUse(kBtu)\":  # Exclure la cible elle-m√™me car toujours √† 1.0\n",
    "        print(f\"   {var:30} : {corr_value:+.3f}\")\n",
    "\n",
    "# Target 2 : √âmissions CO2\n",
    "print(\"\\n TARGET 2 : TotalGHGEmissions - √âmissions de CO2\")\n",
    "target2_corr = corr_matrix[\"TotalGHGEmissions\"].sort_values(ascending=False)\n",
    "for var, corr_value in target2_corr.items():\n",
    "    if var != \"TotalGHGEmissions\":\n",
    "        print(f\"   {var:30} : {corr_value:+.3f}\")\n",
    "\n",
    "print(\n",
    "    \"\\n ANALYSE : Les deux targets sont fortement corr√©l√©es (+0.860), donc les m√™mes features seront pertinentes.\"\n",
    ")\n",
    "print(\n",
    "    \"    Choix final : SiteEnergyUse(kBtu) et TotalGHGEmissions car 0% de valeurs manquantes.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã Synth√®se de l'Analyse Exploratoire\n",
    "\n",
    "#### Nettoyage et Pr√©paration des Donn√©es\n",
    "\n",
    "**1. Restriction au p√©rim√®tre pertinent :**\n",
    "\n",
    "- **Exclus** : 1708 b√¢timents \"Multifamily\" (habitations hors p√©rim√®tre).\n",
    "- **Conserv√©s** : 1650 b√¢timents non-r√©sidentiels (apr√®s suppression des valeurs n√©gatives/nulles).\n",
    "\n",
    "**2. Colonnes supprim√©es (arguments m√©tier) :**\n",
    "\n",
    "- **>50% vide** : `Comments`, `YearsENERGYSTARCertified` ‚Üí Trop peu d'information exploitable.\n",
    "- **Constantes** : `DataYear`, `City`, `State` ‚Üí Aucun pouvoir discriminant (variance nulle).\n",
    "- **Hors cible** : `Outlier` ‚Üí Gestion manuelle des outliers pr√©f√©r√©e.\n",
    "- **‚ö†Ô∏è Exception** : `ThirdLargestPropertyUseType` (50% NaN) **conserv√©e** ‚Üí NaN = \"pas de 3√®me usage\" = information utile.\n",
    "\n",
    "**3. Lignes supprim√©es :**\n",
    "\n",
    "- **16 b√¢timents** avec Surface ‚â§ 0 ou √ânergie ‚â§ 0 (incoh√©rence m√©tier).\n",
    "- **1 b√¢timent** avec √©missions CO2 n√©gatives (impossible physiquement).\n",
    "\n",
    "**4. Dataset final :**\n",
    "\n",
    "- **1649 b√¢timents** √ó **40 colonnes** (apr√®s nettoyage complet).\n",
    "- **Targets choisies** :\n",
    "  - `SiteEnergyUse(kBtu)` - Consommation √©nerg√©tique\n",
    "  - `TotalGHGEmissions` - √âmissions de CO2\n",
    "  - Raison : 0% de valeurs manquantes pour les deux, forte corr√©lation (+0.860) validant leur coh√©rence.\n",
    "- **Variables d'usage conserv√©es** : Largest, Second, Third (complexit√© du b√¢timent ‚Üí pr√©dictif)\n",
    "\n",
    "---\n",
    "\n",
    "#### Insights Cl√©s\n",
    "\n",
    "**1. Distribution des consommations :**\n",
    "\n",
    "- **Forte asym√©trie √† droite** (Moyenne >> M√©diane).\n",
    "- Moyenne : ~8.4M kBtu | M√©diane : ~2.5M kBtu.\n",
    "- **Cons√©quence** : Une transformation logarithmique de la target sera indispensable pour la mod√©lisation.\n",
    "\n",
    "**2. Influence du Type de B√¢timent (Usage) :**\n",
    "\n",
    "- Le **PrimaryPropertyType** est un facteur discriminant majeur.\n",
    "- **Gros consommateurs** : H√¥pitaux, Supermarch√©s, Data Centers.\n",
    "- **Faibles consommateurs** : Entrep√¥ts, Lieux de culte.\n",
    "\n",
    "**3. Analyse de Corr√©lation (9 variables num√©riques cl√©s) :**\n",
    "\n",
    "Nous avons √©cart√© les variables de consommation (√âlec/Gaz) pour √©viter le data leakage. Voici les vrais moteurs physiques :\n",
    "\n",
    "**Pour Target 1 (Consommation √ânerg√©tique) :**\n",
    "\n",
    "- **`LargestPropertyUseTypeGFA` (+0.846)** : La surface d√©di√©e √† l'usage principal est le pr√©dicteur le plus fort. C'est la combinaison surface √ó intensit√© d'usage qui explique la consommation.\n",
    "- **`PropertyGFATotal` (+0.809)** : La surface totale reste un facteur majeur (relation quasi-lin√©aire sur √©chelle log).\n",
    "- **`NumberofBuildings` (+0.713)** : La complexit√© du site (Campus, H√¥pitaux multi-b√¢timents) est un indicateur tr√®s fort.\n",
    "- **`SecondLargestPropertyUseTypeGFA` (+0.671)** : Le 2√®me usage contribue √©galement √† la diversit√© √©nerg√©tique.\n",
    "- **`ThirdLargestPropertyUseTypeGFA` (+0.330)** : La pr√©sence d'un 3√®me usage distinct indique une complexit√© fonctionnelle (ex: h√¥pital avec data center).\n",
    "- **`NumberofFloors` (+0.219)** : La hauteur joue un r√¥le secondaire.\n",
    "- **`YearBuilt` (+0.064)** : Pas de corr√©lation lin√©aire directe. L'√¢ge joue un r√¥le complexe (non-lin√©aire) qui n√©cessitera des mod√®les adapt√©s (arbres de d√©cision).\n",
    "\n",
    "**Pour Target 2 (√âmissions CO2) :**\n",
    "\n",
    "- **`SiteEnergyUse(kBtu)` (+0.860)** : Corr√©lation tr√®s forte avec l'√©nergie (logique physique : plus d'√©nergie = plus d'√©missions).\n",
    "- **`LargestPropertyUseTypeGFA` (+0.575)** : L'usage principal a un impact majeur sur les √©missions (certains usages √©mettent plus de CO2).\n",
    "- **`SecondLargestPropertyUseTypeGFA` (+0.539)** : La diversit√© d'usage contribue significativement aux √©missions.\n",
    "- **`PropertyGFATotal` (+0.528)** : La surface totale a moins d'impact direct sur les √©missions que sur l'√©nergie (le type d'√©nergie utilis√©e compte plus).\n",
    "- **`NumberofBuildings` (+0.418)** : Impact mod√©r√© de la complexit√© du site.\n",
    "- **`ThirdLargestPropertyUseTypeGFA` (+0.387)** : La complexit√© fonctionnelle joue un r√¥le pour les √©missions.\n",
    "- **`NumberofFloors` (+0.130)** : Corr√©lation faible avec les √©missions.\n",
    "- **`YearBuilt` (+0.051)** : Aucune corr√©lation lin√©aire directe.\n",
    "\n",
    "**üí° Insight cl√© :** Les variables de **surface par type d'usage** (Largest/Second/Third GFA) sont des pr√©dicteurs puissants car elles capturent √† la fois la taille ET l'intensit√© √©nerg√©tique de chaque fonction du b√¢timent. Un h√¥pital de 10 000 m¬≤ consomme bien plus qu'un entrep√¥t de m√™me surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE AVANT MOD√âLISATION\n",
    "\n",
    "# Supprimer les √©missions n√©gatives (physiquement impossibles)\n",
    "nb_negatif = len(df[df[\"TotalGHGEmissions\"] < 0])\n",
    "if nb_negatif > 0:\n",
    "    print(f\"   Suppression de {nb_negatif} b√¢timent(s) avec √©missions n√©gatives\")\n",
    "    df = df[df[\"TotalGHGEmissions\"] >= 0]\n",
    "\n",
    "# V√©rification\n",
    "print(f\" Dataset final pr√™t pour la mod√©lisation : {df.shape}\")\n",
    "print(f\"   - B√¢timents : {df.shape[0]}\")\n",
    "print(f\"   - Variables : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Analyse Exploratoire COMPL√àTE\n",
    "\n",
    "**R√©sum√© des accomplissements :**\n",
    "\n",
    "1. **Compr√©hension du dataset** : Explication d√©taill√©e des colonnes cl√©s et de leur r√¥le\n",
    "2. **Nettoyage structur√©** : Suppression justifi√©e de colonnes/lignes avec tra√ßabilit√© compl√®te\n",
    "3. **Statistiques descriptives** : R√©sum√© des variables cibles (√©nergie, CO2) avec d√©tection d'outliers\n",
    "4. **Visualisations pertinentes** :\n",
    "   - Boxplots comparatifs (22 types de b√¢timents class√©s par consommation ET √©missions CO2)\n",
    "   - Scatter plot avec ligne de tendance OLS (corr√©lation Surface vs √ânergie, color√© par CO2)\n",
    "   - Heatmap de corr√©lation (relations entre variables cl√©s + **comparaison des 2 targets**)\n",
    "5. **Choix des targets justifi√©** :\n",
    "   - **Target 1** : `SiteEnergyUse(kBtu)` - Consommation √©nerg√©tique\n",
    "   - **Target 2** : `TotalGHGEmissions` - √âmissions de CO2\n",
    "   - Raison : 0% de valeurs manquantes, forte corr√©lation (+0.860), profils pr√©dictifs diff√©rents\n",
    "6. **Identification des incoh√©rences** : Valeurs n√©gatives/nulles d√©tect√©es et supprim√©es\n",
    "\n",
    "**Dataset final pr√™t pour la mod√©lisation : 1649 b√¢timents √ó 40 colonnes**\n",
    "**Objectif : Construire DEUX mod√®les de pr√©diction (un par target)**\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Ressources Compl√©mentaires\n",
    "\n",
    "Pour approfondir l'esprit d'une analyse exploratoire, consultez :\n",
    "\n",
    "https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python\n",
    "\n",
    "_(Ce notebook n'est pas un mod√®le √† suivre strictement, mais une source d'inspiration)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√©lisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Mod√®les\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Objectif :** Cr√©er de nouvelles variables (features) √† partir des colonnes existantes pour enrichir le pouvoir pr√©dictif du mod√®le.\n",
    "\n",
    "**‚ö†Ô∏è R√àGLE D'OR : Pas de Data Leakage !**\n",
    "\n",
    "- Ne jamais utiliser des variables qui contiennent d√©j√† la r√©ponse (quantit√©s d'Electricity, NaturalGas, Steam)\n",
    "- Cr√©er uniquement des features d√©riv√©es de caract√©ristiques **structurelles**, **d'usage** ou **g√©ographiques**\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Pistes de R√©flexion :**\n",
    "\n",
    "**1. Temporalit√© (√Çge du b√¢timent) :**\n",
    "\n",
    "- `BuildingAge` : 2016 - YearBuilt\n",
    "- Possibilit√© de cr√©er des tranches d'√¢ge (Ex: <10 ans, 10-30 ans, >30 ans)\n",
    "\n",
    "**2. Structure du b√¢timent :**\n",
    "\n",
    "- `HasMultipleBuildings` : Indicateur binaire (0/1) si le site contient plusieurs b√¢timents\n",
    "- `FloorsPerBuilding` : Ratio NumberofFloors / NumberofBuildings (si >1 b√¢timent)\n",
    "\n",
    "**3. Multi-Usage (Proportion) :**\n",
    "\n",
    "- `HasSecondaryUse` : Indicateur binaire si usage secondaire existe\n",
    "- `SecondaryUseProportion` : SecondLargestPropertyUseTypeGFA / PropertyGFATotal (si disponible)\n",
    "\n",
    "**4. Sources d'√©nergie (Pr√©sence SANS quantit√©) :**\n",
    "\n",
    "- `HasElectricity` : 1 si Electricity(Kbtu) > 0, sinon 0\n",
    "- `HasNaturalGas` : 1 si NaturalGas(therms) > 0, sinon 0\n",
    "- `HasSteam` : 1 si SteamUse(kBtu) > 0, sinon 0\n",
    "- ‚Üí Ces features structurelles indiquent l'√©quipement disponible SANS r√©v√©ler l'intensit√© de consommation\n",
    "\n",
    "**5. Localisation :**\n",
    "\n",
    "- **`DistanceToCenter`** : Distance g√©ographique entre le b√¢timent et le centre-ville de Seattle\n",
    "  - Utiliser les coordonn√©es `Latitude` et `Longitude` du dataset\n",
    "  - Centre-ville de Seattle : **Latitude 47.6062, Longitude -122.3321** (Pike Place Market)\n",
    "  - Formule de distance : **Haversine** (pour calculer la distance en km entre 2 points GPS)\n",
    "  - **Pourquoi c'est important ?** Les b√¢timents en p√©riph√©rie consomment diff√©remment (bureaux vs zones industrielles)\n",
    "- `Neighborhood` : Optionnel - Regroupement par ZipCode ou CouncilDistrictCode (haute cardinalit√© ‚Üí cr√©er des tranches)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "print(\"üõ†Ô∏è Cr√©ation des nouvelles features...\\n\")\n",
    "\n",
    "# Feature 1 : Age du b√¢timent\n",
    "current_year = 2016\n",
    "df[\"BuildingAge\"] = current_year - df[\"YearBuilt\"]\n",
    "print(\"‚úÖ Feature 1 : BuildingAge\")\n",
    "print(f\"   √Çge moyen : {df['BuildingAge'].mean():.1f} ans\")\n",
    "\n",
    "# Feature 2 : Indicateur site multi-b√¢timents (0 ou 1)\n",
    "df[\"HasMultipleBuildings\"] = (df[\"NumberofBuildings\"] > 1).astype(int)\n",
    "print(\"\\n‚úÖ Feature 2 : HasMultipleBuildings\")\n",
    "print(\n",
    "    f\"   {df['HasMultipleBuildings'].sum()} sites ({df['HasMultipleBuildings'].mean():.1%})\"\n",
    ")\n",
    "\n",
    "# Feature 3 : Ratio √©tages par b√¢timent\n",
    "df[\"FloorsPerBuilding\"] = df.apply(\n",
    "    lambda row: row[\"NumberofFloors\"] / row[\"NumberofBuildings\"]\n",
    "    if row[\"NumberofBuildings\"] > 0 and pd.notna(row[\"NumberofFloors\"])\n",
    "    else 0,\n",
    "    axis=1,\n",
    ")\n",
    "print(\"\\n‚úÖ Feature 3 : FloorsPerBuilding\")\n",
    "print(f\"   Moyenne : {df['FloorsPerBuilding'].mean():.1f} √©tages/b√¢timent\")\n",
    "\n",
    "# Feature 4 : Indicateur usage secondaire\n",
    "df[\"HasSecondaryUse\"] = df[\"SecondLargestPropertyUseType\"].notna().astype(int)\n",
    "print(\"\\n‚úÖ Feature 4 : HasSecondaryUse\")\n",
    "print(\n",
    "    f\"   {df['HasSecondaryUse'].sum()} b√¢timents ({df['HasSecondaryUse'].mean():.1%})\"\n",
    ")\n",
    "\n",
    "\n",
    "# Feature 5 : Distance au centre-ville (Haversine, formule universelle de distance entre 2 points GPS sur une sph√®re)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calcule la distance en km entre deux points GPS\"\"\"\n",
    "    R = 6371  # Rayon de la Terre en km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = (\n",
    "        sin(dlat / 2) ** 2\n",
    "        + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "center_lat, center_lon = 47.6062, -122.3321  # Pike Place Market, Seattle\n",
    "df[\"DistanceToCenter\"] = df.apply(\n",
    "    lambda row: haversine(row[\"Latitude\"], row[\"Longitude\"], center_lat, center_lon)\n",
    "    if pd.notna(row[\"Latitude\"]) and pd.notna(row[\"Longitude\"])\n",
    "    else 0,\n",
    "    axis=1,\n",
    ")\n",
    "print(\"\\n‚úÖ Feature 5 : DistanceToCenter\")\n",
    "print(f\"   Distance moyenne : {df['DistanceToCenter'].mean():.2f} km\")\n",
    "print(f\"   Distance max : {df['DistanceToCenter'].max():.2f} km\")\n",
    "\n",
    "# Features 6-8 : Indicateurs sources d'√©nergie (pr√©sence SANS quantit√©)\n",
    "\n",
    "# Remplace NaN par 0 avant comparaison et conversion en int\n",
    "df[\"HasElectricity\"] = (df[\"Electricity(kBtu)\"].fillna(0) > 0).astype(int)\n",
    "df[\"HasNaturalGas\"] = (df[\"NaturalGas(therms)\"].fillna(0) > 0).astype(int)\n",
    "df[\"HasSteam\"] = (df[\"SteamUse(kBtu)\"].fillna(0) > 0).astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Features 6-8 : Indicateurs sources d'√©nergie\")\n",
    "print(\n",
    "    f\"   √âlectricit√© : {df['HasElectricity'].sum()} ({df['HasElectricity'].mean():.1%})\"\n",
    ")\n",
    "print(\n",
    "    f\"   Gaz Naturel : {df['HasNaturalGas'].sum()} ({df['HasNaturalGas'].mean():.1%})\"\n",
    ")\n",
    "print(f\"   Vapeur      : {df['HasSteam'].sum()} ({df['HasSteam'].mean():.1%})\")\n",
    "\n",
    "# Feature 9 : Interaction Surface √ó Gaz Naturel\n",
    "# Hypoth√®se : Les grands b√¢timents avec gaz consomment/√©mettent diff√©remment\n",
    "df[\"SurfaceGasInteraction\"] = df[\"PropertyGFATotal\"] * df[\"HasNaturalGas\"]\n",
    "print(\"\\n‚úÖ Feature 9 : SurfaceGasInteraction\")\n",
    "print(\"   Interaction Surface √ó Gaz (utile pour pr√©dire CO2)\")\n",
    "\n",
    "# Feature 10 : Ratio √ânergie par Surface\n",
    "\n",
    "# Cr√©er une nouvelle feature \"EnergyPerSurface\" qui est le ratio entre la consommation d'√©nergie et la surface totale du b√¢timent.\n",
    "# Attention au risque de data leakage avec Target 1.\n",
    "df[\"EnergyPerSurface\"] = df.apply(\n",
    "    lambda row: row[\"SiteEnergyUse(kBtu)\"] / row[\"PropertyGFATotal\"]\n",
    "    if row[\"PropertyGFATotal\"] > 0\n",
    "    else 0,\n",
    "    axis=1,\n",
    ")\n",
    "print(\"\\n‚úÖ Feature 10 : EnergyPerSurface\")\n",
    "print(f\"   Ratio moyen : {df['EnergyPerSurface'].mean():.2f} kBtu/sqft\")\n",
    "print(\"   ‚ö†Ô∏è ATTENTION : Cette feature sera EXCLUE pour Target 1 (data leakage)\")\n",
    "print(\"   ‚úÖ Utilisable pour Target 2 (CO2) si Target 1 exclue\")\n",
    "\n",
    "print(\"\\nüéâ Feature Engineering termin√© ! 10 nouvelles features cr√©√©es\")\n",
    "print(f\"   Taille du dataset : {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectif :** Pr√©parer le dataset final pour l'entra√Ænement des mod√®les de Machine Learning.\n",
    "\n",
    "Cette section va structurer les donn√©es en :\n",
    "\n",
    "- **X** : DataFrame des features (variables explicatives)\n",
    "- **y** : Series de la target (variable √† pr√©dire)\n",
    "\n",
    "**Organisation en 4 √©tapes :**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ PARTIE 1 : PR√âDICTION DE LA CONSOMMATION √âNERG√âTIQUE\n",
    "\n",
    "**Target :** `SiteEnergyUse(kBtu)` - Consommation totale d'√©nergie du b√¢timent\n",
    "\n",
    "**Strat√©gie :** Nous allons exclure `TotalGHGEmissions` (Target 2) des features pour √©viter le data leakage.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 1 : Pr√©paration des Donn√©es\n",
    "\n",
    "**Objectif :** Pr√©parer X et y pour la mod√©lisation avec Pipeline sklearn\n",
    "\n",
    "**Ce qu'on va faire :**\n",
    "\n",
    "- S√©lectionner les features (exclusion leakage + identifiants)\n",
    "- Extraire la target `SiteEnergyUse(kBtu)`\n",
    "- Identifier les colonnes num√©riques vs cat√©gorielles\n",
    "- **Utiliser Pipeline + ColumnTransformer** pour automatiser le preprocessing\n",
    "\n",
    "**‚ö†Ô∏è Important :** On exclut `TotalGHGEmissions` (Target 2) ET `EnergyPerSurface` (data leakage) pour Target 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Pr√©paration des donn√©es pour Pipeline sklearn\n",
    "\n",
    "print(\"üìã √âtape 1 : Pr√©paration X et y pour TARGET 1 (Energy)\\n\")\n",
    "\n",
    "# Liste des colonnes √† supprimer (data leakage + identifiants inutiles)\n",
    "leakage_cols = [\n",
    "    # Variables de leakage (composants directs de la target)\n",
    "    \"SiteEnergyUseWN(kBtu)\",\n",
    "    \"SiteEUI(kBtu/sf)\",\n",
    "    \"SiteEUIWN(kBtu/sf)\",\n",
    "    \"SourceEUI(kBtu/sf)\",\n",
    "    \"SourceEUIWN(kBtu/sf)\",\n",
    "    \"Electricity(kWh)\",\n",
    "    \"Electricity(kBtu)\",\n",
    "    \"NaturalGas(therms)\",\n",
    "    \"NaturalGas(kBtu)\",\n",
    "    \"SteamUse(kBtu)\",\n",
    "    \"GHGEmissionsIntensity\",\n",
    "]\n",
    "\n",
    "useless_cols = [\n",
    "    \"OSEBuildingID\",\n",
    "    \"PropertyName\",\n",
    "    \"TaxParcelIdentificationNumber\",\n",
    "    \"Address\",\n",
    "    \"ZipCode\",\n",
    "    \"CouncilDistrictCode\",\n",
    "    \"Neighborhood\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"YearBuilt\",\n",
    "    \"ComplianceStatus\",\n",
    "    \"DefaultData\",\n",
    "    \"ListOfAllPropertyUseTypes\",\n",
    "]\n",
    "\n",
    "special_cols = [\"ENERGYSTARScore\"]\n",
    "\n",
    "cols_to_drop = leakage_cols + useless_cols + special_cols\n",
    "\n",
    "# Suppression s√©curis√©e\n",
    "existing_cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
    "df_clean = df.drop(columns=existing_cols_to_drop)\n",
    "\n",
    "print(f\"üóëÔ∏è  Colonnes supprim√©es : {len(existing_cols_to_drop)}\")\n",
    "\n",
    "# Extraction de la target 1\n",
    "y_energy = df_clean[\"SiteEnergyUse(kBtu)\"].copy()\n",
    "\n",
    "# Exclusion Target 2 + EnergyPerSurface (leakage)\n",
    "cols_to_exclude = [\"SiteEnergyUse(kBtu)\", \"TotalGHGEmissions\", \"EnergyPerSurface\"]\n",
    "X_energy = df_clean.drop(\n",
    "    columns=[col for col in cols_to_exclude if col in df_clean.columns]\n",
    ")\n",
    "\n",
    "# Transformation log de la target\n",
    "y_energy_log = np.log1p(y_energy)\n",
    "\n",
    "print(f\"‚úÖ X_energy : {X_energy.shape}\")\n",
    "print(f\"‚úÖ y_energy_log : {y_energy_log.shape}\")\n",
    "print(\"\\n‚úÖ √âtape 1 termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 2 : Construction du Pipeline de Preprocessing\n",
    "\n",
    "**Pourquoi utiliser un Pipeline ?**\n",
    "\n",
    "‚úÖ **√âvite le data leakage** : Le preprocessing (scaling, encoding) est appliqu√© UNIQUEMENT sur le train √† chaque fold de CV  \n",
    "‚úÖ **Code propre** : Tout le preprocessing est encapsul√© dans un seul objet  \n",
    "‚úÖ **Reproductible** : Facile √† r√©utiliser et d√©ployer\n",
    "\n",
    "**Ce que fait notre Pipeline :**\n",
    "\n",
    "1. **Colonnes num√©riques** :\n",
    "\n",
    "   - Imputation m√©diane (valeurs manquantes)\n",
    "   - StandardScaler (normalisation)\n",
    "\n",
    "2. **Colonnes cat√©gorielles** :\n",
    "\n",
    "   - Imputation mode (valeurs manquantes)\n",
    "   - OneHotEncoder (encodage)\n",
    "\n",
    "3. **Mod√®le** : LinearRegression / RandomForest / SVR / LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Construction du Pipeline de Preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"üîß √âtape 2 : Construction du Pipeline\\n\")\n",
    "\n",
    "# Identification auto des colonnes num√©riques vs cat√©gorielles\n",
    "numeric_features = X_energy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_features = X_energy.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(f\"üìä Features num√©riques   : {len(numeric_features)}\")\n",
    "print(f\"üìä Features cat√©gorielles : {len(categorical_features)}\")\n",
    "\n",
    "# Pipeline pour les features num√©riques\n",
    "\"\"\" On impute par la m√©diane puis on scale.\n",
    "    Exemple : Si un chiffre manque, on remplace par la m√©diane de la colonne (la m√©diance est robuste aux outliers)\n",
    "    \n",
    "    On transforme ensuite les donn√©es pour qu'elles aient une moyenne de 0 et un √©cart-type de 1 (StandardScaler)\n",
    "    Exemple : Si un b√¢timent a 3 √©tages et qu'un autre en a 10, apr√®s scaling, le b√¢timent √† 10 √©tages aura une valeur plus √©lev√©e mais dans une √©chelle comparable aux autres features.\n",
    "\"\"\"\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# Pipeline pour les features cat√©gorielles\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # Si une cat√©gorie manque, on remplace par la valeur la plus fr√©quente (mode)\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # Encodage OneHot : transforme chaque cat√©gorie en une colonne binaire (0 ou 1)\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ColumnTransformer : applique le bon pipeline √† chaque type de colonne\n",
    "# Fonctionnement : Il d√©cide quelle transformation appliquer √† chaque colonne en fonction de son type (num√©rique ou cat√©gorielle)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",  # On ne garde que les colonnes sp√©cifi√©es\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline de preprocessing cr√©√©\")\n",
    "print(\"   - Imputation + Scaling pour num√©riques\")\n",
    "print(\"   - Imputation + OneHot pour cat√©gorielles\")\n",
    "\n",
    "# On choisit la m√©diane pour boucher les trous car elle n'est pas fauss√©e par tes \"b√¢timents g√©ants\" (Outliers). On parle de la m√©diane de la colonne concern√©e (calcul√©e sur les donn√©es d'entra√Ænement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 3 : Cross-Validation avec KFold\n",
    "\n",
    "**Pourquoi Cross-Validation plut√¥t que Train/Test simple ?**\n",
    "\n",
    "‚ùå **Probl√®me du Train/Test simple** :\n",
    "\n",
    "- Le r√©sultat d√©pend du `random_state` (coup de chance/malchance)\n",
    "- Une seule √©valuation ‚Üí variance √©lev√©e\n",
    "- Pas robuste\n",
    "\n",
    "‚úÖ **Avantages de la Cross-Validation (K-Fold)** :\n",
    "\n",
    "- **K=5** : On d√©coupe les donn√©es en 5 parties\n",
    "- Le mod√®le est entra√Æn√© **5 fois** avec des validations diff√©rentes\n",
    "- On moyenne les r√©sultats ‚Üí **estimation robuste**\n",
    "- Chaque observation est utilis√©e **une fois** en validation\n",
    "\n",
    "**üí° Bonus** : On garde `return_train_score=True` pour d√©tecter l'overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"üîÑ √âtape 3 : Configuration Cross-Validation\\n\")\n",
    "\n",
    "# KFold avec 5 splits\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# M√©triques √† calculer\n",
    "scoring = {\n",
    "    \"r2\": \"r2\",\n",
    "    \"mae\": \"neg_mean_absolute_error\",\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Cross-Validation configur√©e :\")\n",
    "print(\"   - K-Fold : 5 splits\")\n",
    "print(\"   - Shuffle : True (m√©lange al√©atoire)\")\n",
    "print(\"   - M√©triques : R¬≤, MAE, RMSE\")\n",
    "print(\"\\nüí° Chaque mod√®le sera √©valu√© 5 fois sur des donn√©es diff√©rentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 4 : Mod√©lisation avec Pipeline + Cross-Validation\n",
    "\n",
    "**Algorithmes test√©s :**\n",
    "\n",
    "1. **Linear Regression** : Baseline simple\n",
    "2. **Random Forest** (Bagging) : Parall√©lisation de 100 arbres, robuste aux outliers\n",
    "3. **SVR** (RBF kernel) : Mod√®le non-lin√©aire avec noyau gaussien\n",
    "4. **LightGBM** (Boosting) : Mod√®le gradient boosting, capte les interactions complexes\n",
    "\n",
    "**Processus pour chaque mod√®le :**\n",
    "\n",
    "1. Cr√©ation du Pipeline (preprocessing + mod√®le)\n",
    "2. Cross-validation K-Fold (5 splits)\n",
    "3. Calcul des m√©triques moyennes (R¬≤, MAE, RMSE)\n",
    "4. D√©tection de l'overfitting (√©cart Train/CV)\n",
    "\n",
    "**‚è±Ô∏è Estimation** : ~2-3 minutes (LightGBM + RF sur 5 folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Mod√©lisation avec Pipeline + Cross-Validation (TARGET 1)\n",
    "\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "# Supprimer les warnings sklearn sur les feature names\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "\n",
    "print(\"ü§ñ MOD√âLISATION TARGET 1 (Energy) - Pipeline + Cross-Validation\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dictionnaire des mod√®les √† tester\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=100, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=1.0, epsilon=0.1),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        n_estimators=100, random_state=42, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Stockage des r√©sultats\n",
    "results_energy = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîÑ Cross-Validation pour {model_name}...\")\n",
    "\n",
    "    # Construction du pipeline complet\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_results = cross_validate(\n",
    "        pipeline,\n",
    "        X_energy,\n",
    "        y_energy_log,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Extraction des m√©triques (conversion en positif pour MAE/RMSE)\n",
    "    r2_train_mean = cv_results[\"train_r2\"].mean()\n",
    "    r2_cv_mean = cv_results[\"test_r2\"].mean()\n",
    "    r2_cv_std = cv_results[\"test_r2\"].std()\n",
    "\n",
    "    mae_cv_mean = -cv_results[\"test_mae\"].mean()\n",
    "    mae_cv_std = cv_results[\"test_mae\"].std()\n",
    "\n",
    "    rmse_cv_mean = -cv_results[\"test_rmse\"].mean()\n",
    "    rmse_cv_std = cv_results[\"test_rmse\"].std()\n",
    "\n",
    "    overfit_gap = r2_train_mean - r2_cv_mean\n",
    "\n",
    "    # Affichage\n",
    "    print(f\"‚úÖ {model_name}\")\n",
    "    print(f\"   R¬≤ Train : {r2_train_mean:.4f}\")\n",
    "    print(f\"   R¬≤ CV    : {r2_cv_mean:.4f} ¬± {r2_cv_std:.4f}\")\n",
    "    print(f\"   MAE CV   : {mae_cv_mean:.4f} ¬± {mae_cv_std:.4f}\")\n",
    "    print(f\"   RMSE CV  : {rmse_cv_mean:.4f} ¬± {rmse_cv_std:.4f}\")\n",
    "\n",
    "    # Diagnostic overfitting\n",
    "    if overfit_gap > 0.15:\n",
    "        print(f\"   ‚ö†Ô∏è Surapprentissage d√©tect√© (√©cart = {overfit_gap:.4f})\")\n",
    "    elif overfit_gap < -0.05:\n",
    "        print(\"   ‚ö†Ô∏è Sous-apprentissage possible\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Bon √©quilibre (√©cart = {overfit_gap:.4f})\")\n",
    "\n",
    "    # Stockage\n",
    "    results_energy.append(\n",
    "        {\n",
    "            \"Mod√®le\": model_name,\n",
    "            \"R¬≤ CV (mean)\": r2_cv_mean,\n",
    "            \"R¬≤ CV (std)\": r2_cv_std,\n",
    "            \"MAE CV\": mae_cv_mean,\n",
    "            \"RMSE CV\": rmse_cv_mean,\n",
    "            \"R¬≤ Train\": r2_train_mean,\n",
    "            \"Overfit Gap\": overfit_gap,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Cross-Validation termin√©e pour les 4 mod√®les\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Comparaison des Mod√®les (TARGET 1 - Energy)\n",
    "\n",
    "**Crit√®re de s√©lection** : R¬≤ CV (mean)\n",
    "\n",
    "Le **R¬≤ CV moyen** repr√©sente la performance r√©elle attendue en production, car il est calcul√© sur des donn√©es jamais vues pendant l'entra√Ænement.\n",
    "\n",
    "**Lecture du tableau :**\n",
    "\n",
    "- **R¬≤ CV (mean)** : Performance moyenne sur les 5 folds (plus √©lev√© = meilleur)\n",
    "- **R¬≤ CV (std)** : Variabilit√© entre les folds (plus faible = plus stable)\n",
    "- **Overfit Gap** : √âcart R¬≤ Train - R¬≤ CV (>0.15 = surapprentissage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Tableau comparatif et identification du champion\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä TABLEAU R√âCAPITULATIF - TARGET 1 (Energy)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "comparison_df_energy = pd.DataFrame(results_energy).sort_values(\n",
    "    by=\"R¬≤ CV (mean)\", ascending=False\n",
    ")\n",
    "\n",
    "print(comparison_df_energy.to_string(index=False))\n",
    "\n",
    "# Identification du meilleur mod√®le\n",
    "best_model_name_energy = comparison_df_energy.iloc[0][\"Mod√®le\"]\n",
    "best_r2_cv_energy = comparison_df_energy.iloc[0][\"R¬≤ CV (mean)\"]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üèÜ MEILLEUR MOD√àLE (selon R¬≤ CV) : {best_model_name_energy}\")\n",
    "print(f\"   R¬≤ CV = {best_r2_cv_energy:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Comparaison termin√©e pour TARGET 1 (Energy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîß Optimisation des Hyperparam√®tres - TARGET 1 (Energy)\n",
    "\n",
    "**üéØ Objectif :** Optimiser les hyperparam√®tres du mod√®le champion (Random Forest) identifi√© par Cross-Validation.\n",
    "\n",
    "**M√©thode : GridSearchCV**\n",
    "\n",
    "- **Principe** : Teste toutes les combinaisons possibles d'hyperparam√®tres\n",
    "- **Validation** : Utilise Cross-Validation (cv=5) pour chaque combinaison\n",
    "- **Avantage** : √âvite le surapprentissage en validant sur donn√©es non vues\n",
    "- **Combinaisons** : ~100 combinaisons (recommandation OpenClassrooms)\n",
    "\n",
    "**üí° GridSearchCV + Pipeline + CV = Solution robuste**\n",
    "\n",
    "- Pipeline emp√™che le data leakage (preprocessing uniquement sur train fold)\n",
    "- CV (5 folds) donne une estimation robuste pour chaque combinaison\n",
    "- Pas de `y_train_pred` : chaque combinaison est √©valu√©e sur donn√©es non vues\n",
    "\n",
    "**‚ö†Ô∏è Attention :** GridSearchCV ne garantit PAS toujours une am√©lioration. Les hyperparam√®tres par d√©faut peuvent d√©j√† √™tre optimaux pour vos donn√©es.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : GridSearchCV pour Random Forest (TARGET 1)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"üîß OPTIMISATION HYPERPARAM√àTRES - TARGET 1 (Energy)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Mod√®le √† optimiser : {best_model_name_energy}\")\n",
    "print(f\"Performance de base (R¬≤ CV) : {best_r2_cv_energy:.4f}\\n\")\n",
    "\n",
    "# Grille d'hyperparam√®tres (limit√©e √† ~100 combinaisons)\n",
    "param_grid_energy = {\n",
    "    # Le nombre d'arbres dans la for√™t\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    # La hauteur maximale de chaque arbre\n",
    "    \"model__max_depth\": [10, 20, 30, None],\n",
    "    # Le nombre minimum de b√¢timents requis avant de cr√©er une nouvelle branche\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    # Le nombre minimum de b√¢timents qui doivent √™tre pr√©sents dans une feuille (le r√©sultat final)\n",
    "    \"model__min_samples_leaf\": [1, 2],  # 2 valeurs\n",
    "    # Le nombre de features √† consid√©rer lors de la recherche du meilleur split\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],  # 2 valeurs\n",
    "}\n",
    "\n",
    "# Calcul du nombre de combinaisons\n",
    "n_combinations = 3 * 4 * 3 * 2 * 2\n",
    "print(f\"üìä Nombre de combinaisons √† tester : {n_combinations}\")\n",
    "print(f\"‚è±Ô∏è Temps estim√© : {n_combinations * 5 // 60} minutes (environ)\\n\")\n",
    "\n",
    "# Construction du pipeline avec le meilleur mod√®le\n",
    "pipeline_to_optimize = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(random_state=42, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# GridSearchCV avec Cross-Validation\n",
    "print(\"üîÑ Lancement de GridSearchCV (peut prendre plusieurs minutes)...\\n\")\n",
    "\n",
    "grid_search_energy = GridSearchCV(\n",
    "    estimator=pipeline_to_optimize,\n",
    "    param_grid=param_grid_energy,\n",
    "    cv=cv,  # R√©utilise le KFold(5) d√©fini pr√©c√©demment (cross-validation)\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "# Entra√Ænement (teste toutes les combinaisons)\n",
    "grid_search_energy.fit(X_energy, y_energy_log)\n",
    "\n",
    "# R√©sultats\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ GridSearchCV termin√© !\")\n",
    "print(\"\\nüèÜ MEILLEURS HYPERPARAM√àTRES TROUV√âS :\")\n",
    "for param, value in grid_search_energy.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(\"\\nüìä PERFORMANCES :\")\n",
    "print(f\"   R¬≤ CV (optimis√©) : {grid_search_energy.best_score_:.4f}\")\n",
    "print(f\"   R¬≤ CV (base)     : {best_r2_cv_energy:.4f}\")\n",
    "\n",
    "# Calcul de la diff√©rence\n",
    "improvement_energy = grid_search_energy.best_score_ - best_r2_cv_energy\n",
    "print(\n",
    "    f\"\\nüìà Am√©lioration : {improvement_energy:+.4f} ({improvement_energy / best_r2_cv_energy * 100:+.2f}%)\"\n",
    ")\n",
    "\n",
    "if improvement_energy > 0:\n",
    "    print(\"   ‚úÖ GridSearchCV a am√©lior√© les performances !\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è GridSearchCV n'a pas am√©lior√© les performances.\")\n",
    "    print(\"   ‚Üí Les hyperparam√®tres par d√©faut √©taient d√©j√† optimaux.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä D√©cision Finale - TARGET 1 (Energy)\n",
    "\n",
    "**Question :** Quel mod√®le utiliser pour la pr√©diction finale ?\n",
    "\n",
    "**Crit√®re de d√©cision :** R¬≤ CV (plus √©lev√© = meilleur)\n",
    "\n",
    "Nous allons comparer :\n",
    "\n",
    "1. **Mod√®le de base** : Random Forest avec hyperparam√®tres par d√©faut\n",
    "2. **Mod√®le optimis√©** : Random Forest avec hyperparam√®tres optimis√©s par GridSearchCV\n",
    "\n",
    "Le mod√®le avec le **meilleur R¬≤ CV** sera retenu pour :\n",
    "\n",
    "- L'analyse de Feature Importance\n",
    "- Les pr√©dictions futures\n",
    "- La conclusion du projet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Comparaison Mod√®le de Base vs Mod√®le Optimis√© (TARGET 1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä COMPARAISON FINALE - TARGET 1 (Energy)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Cr√©ation du DataFrame de comparaison\n",
    "comparison_final_energy = pd.DataFrame(\n",
    "    {\n",
    "        \"Mod√®le\": [\"Random Forest (Base)\", \"Random Forest (Optimis√©)\"],\n",
    "        \"R¬≤ CV\": [best_r2_cv_energy, grid_search_energy.best_score_],\n",
    "        \"Hyperparam√®tres\": [\"Par d√©faut\", \"GridSearchCV\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tri par R¬≤ CV d√©croissant\n",
    "comparison_final_energy = comparison_final_energy.sort_values(\n",
    "    \"R¬≤ CV\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(comparison_final_energy.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Identification du meilleur mod√®le FINAL\n",
    "if best_r2_cv_energy >= grid_search_energy.best_score_:\n",
    "    final_model_name_energy = \"Random Forest (Base)\"\n",
    "    final_r2_energy = best_r2_cv_energy\n",
    "    # Reconstruire le pipeline de base\n",
    "    final_pipeline_energy = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"model\",\n",
    "                RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    final_pipeline_energy.fit(X_energy, y_energy_log)\n",
    "    print(\"üèÜ MOD√àLE RETENU : Random Forest avec hyperparam√®tres PAR D√âFAUT\")\n",
    "    print(f\"   R¬≤ CV = {final_r2_energy:.4f}\")\n",
    "    print(\n",
    "        \"\\nüí° Conclusion : Les hyperparam√®tres par d√©faut sont optimaux pour ce dataset.\"\n",
    "    )\n",
    "else:\n",
    "    final_model_name_energy = \"Random Forest (Optimis√©)\"\n",
    "    final_r2_energy = grid_search_energy.best_score_\n",
    "    final_pipeline_energy = grid_search_energy.best_estimator_\n",
    "    print(\"üèÜ MOD√àLE RETENU : Random Forest avec hyperparam√®tres OPTIMIS√âS\")\n",
    "    print(f\"   R¬≤ CV = {final_r2_energy:.4f}\")\n",
    "    print(\"\\nüí° Conclusion : GridSearchCV a am√©lior√© les performances.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance - TARGET 1 (Energy)\n",
    "\n",
    "**Objectif** : Identifier les variables les plus importantes pour pr√©dire la consommation √©nerg√©tique.\n",
    "\n",
    "**M√©thode** :\n",
    "\n",
    "1. Entra√Æner le meilleur mod√®le (identifi√© par CV) sur **TOUT** le dataset\n",
    "2. Extraire les feature importances du mod√®le\n",
    "3. Visualiser les TOP 15 features\n",
    "\n",
    "**üí° Pourquoi entra√Æner sur tout le dataset ?**\n",
    "\n",
    "- La CV nous a donn√© une estimation robuste de la performance\n",
    "- Maintenant on veut le meilleur mod√®le possible pour l'interpr√©tation\n",
    "- Utiliser toutes les donn√©es maximise l'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Feature Importance pour le meilleur mod√®le (TARGET 1)\n",
    "\n",
    "print(\"üìä Feature Importance - TARGET 1 (Energy)\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Utilisation du mod√®le FINAL (base ou optimis√© selon comparaison)\n",
    "print(f\"üîÑ Entra√Ænement de {final_model_name_energy} sur tout le dataset...\")\n",
    "\n",
    "# On r√©entra√Æne le pipeline final sur tout le dataset\n",
    "final_pipeline_energy.fit(X_energy, y_energy_log)\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©\\n\")\n",
    "\n",
    "# Extraction du mod√®le du pipeline\n",
    "final_model_energy = final_pipeline_energy.named_steps[\"model\"]\n",
    "\n",
    "# Extraction des feature importances\n",
    "if hasattr(final_model_energy, \"feature_importances_\"):\n",
    "    # Pour RandomForest / LightGBM\n",
    "    feature_importances_energy = final_model_energy.feature_importances_\n",
    "\n",
    "    # R√©cup√©ration des noms de features apr√®s preprocessing\n",
    "    # NumericFeatures gardent leur nom, CategoricalFeatures sont encod√©es\n",
    "    feature_names_energy = (\n",
    "        numeric_features\n",
    "        + final_pipeline_energy.named_steps[\"preprocessor\"]\n",
    "        .named_transformers_[\"cat\"]\n",
    "        .named_steps[\"onehot\"]\n",
    "        .get_feature_names_out(categorical_features)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # Cr√©ation du DataFrame\n",
    "    importance_df_energy = pd.DataFrame(\n",
    "        {\"Feature\": feature_names_energy, \"Importance\": feature_importances_energy}\n",
    "    ).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Calcul des pourcentages\n",
    "    importance_df_energy[\"Importance (%)\"] = (\n",
    "        importance_df_energy[\"Importance\"]\n",
    "        / importance_df_energy[\"Importance\"].sum()\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    # Affichage TOP 15\n",
    "    top_15_energy = importance_df_energy.head(15)\n",
    "\n",
    "    print(\"üîù TOP 15 Features les plus importantes :\\n\")\n",
    "    for idx, row in top_15_energy.iterrows():\n",
    "        print(f\"{row['Feature']:40} : {row['Importance (%)']:5.2f}%\")\n",
    "\n",
    "    # Calcul du TOP 3\n",
    "    top_3_energy = importance_df_energy.head(3)\n",
    "    top_3_pct_energy = top_3_energy[\"Importance (%)\"].sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\nüí° Les 3 features les plus importantes repr√©sentent {top_3_pct_energy:.2f}% de l'importance totale\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {final_model_name_energy} ne supporte pas feature_importances_\")\n",
    "    print(\"   (Normal pour Linear Regression et SVR)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Analyse Feature Importance termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ PARTIE 2 : PR√âDICTION DES √âMISSIONS DE CO2\n",
    "\n",
    "**Target :** `TotalGHGEmissions` - √âmissions totales de gaz √† effet de serre\n",
    "\n",
    "**Diff√©rence avec Target 1 :**\n",
    "- On peut maintenant utiliser `SiteEnergyUse(kBtu)` ET `EnergyPerSurface` comme features\n",
    "- Ces variables sont exclues du leakage car elles ne sont PAS calcul√©es √† partir de CO2\n",
    "\n",
    "**Approche :** M√™me m√©thodologie que Target 1 (Pipeline + Cross-Validation)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 1 : Pr√©paration des Donn√©es (TARGET 2 - CO2)\n",
    "\n",
    "**Diff√©rence majeure avec Target 1** :\n",
    "\n",
    "- ‚úÖ `SiteEnergyUse(kBtu)` est MAINTENANT une feature (pas du leakage)\n",
    "- ‚úÖ `EnergyPerSurface` est MAINTENANT une feature (ratio cr√©√© √† partir de Energy, pas de CO2)\n",
    "\n",
    "**Ce qu'on exclut** :\n",
    "\n",
    "- ‚ùå `TotalGHGEmissions` (c'est notre target)\n",
    "- ‚ùå Variables de leakage CO2 (GHGEmissionsIntensity, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √âtape 2 : Pipeline + Cross-Validation (TARGET 2)\n",
    "\n",
    "**M√™me approche que Target 1** :\n",
    "\n",
    "1. Construction du preprocessor (m√™me que Target 1)\n",
    "2. Configuration K-Fold (K=5)\n",
    "3. Test des 4 algorithmes avec cross_validate\n",
    "4. Identification du champion\n",
    "\n",
    "**üí° Diff√©rence** : `EnergyPerSurface` et `SiteEnergyUse(kBtu)` sont maintenant dans X_co2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Pr√©paration et Mod√©lisation TARGET 2 (CO2) avec Pipeline + CV\n",
    "\n",
    "# Supprimer les warnings sklearn sur les feature names\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üåç TARGET 2 : PR√âDICTION DES √âMISSIONS DE CO2\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "print(\"üìã √âtape 1 : Pr√©paration X_co2 et y_co2\\n\")\n",
    "\n",
    "# Pour CO2, on peut utiliser SiteEnergyUse(kBtu) et EnergyPerSurface\n",
    "y_co2 = df_clean[\"TotalGHGEmissions\"].copy()\n",
    "\n",
    "# Exclusion seulement de la target CO2\n",
    "X_co2 = df_clean.drop(columns=[\"TotalGHGEmissions\"])\n",
    "\n",
    "# Transformation log\n",
    "y_co2_log = np.log1p(y_co2)\n",
    "\n",
    "print(f\"‚úÖ X_co2 : {X_co2.shape}\")\n",
    "print(f\"‚úÖ y_co2_log : {y_co2_log.shape}\")\n",
    "print(\"üí° X_co2 INCLUT maintenant SiteEnergyUse(kBtu) et EnergyPerSurface\\n\")\n",
    "\n",
    "# Identification des colonnes num√©riques vs cat√©gorielles\n",
    "numeric_features_co2 = X_co2.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_features_co2 = X_co2.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(f\"üìä Features num√©riques   : {len(numeric_features_co2)}\")\n",
    "print(f\"üìä Features cat√©gorielles : {len(categorical_features_co2)}\\n\")\n",
    "\n",
    "# Construction du preprocessor pour CO2\n",
    "numeric_transformer_co2 = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer_co2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_co2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer_co2, numeric_features_co2),\n",
    "        (\"cat\", categorical_transformer_co2, categorical_features_co2),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline de preprocessing CO2 cr√©√©\\n\")\n",
    "\n",
    "# Cross-Validation pour les 4 mod√®les\n",
    "print(\"üîÑ √âtape 2 : Cross-Validation avec K-Fold (5 splits)\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Recr√©ation du dictionnaire de mod√®les pour √©viter les warnings\n",
    "models_co2 = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=100, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=1.0, epsilon=0.1),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        n_estimators=100, random_state=42, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "results_co2 = []\n",
    "\n",
    "for model_name, model in models_co2.items():\n",
    "    print(f\"\\nüîÑ Cross-Validation pour {model_name}...\")\n",
    "\n",
    "    pipeline_co2 = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor_co2), (\"model\", model)]\n",
    "    )\n",
    "\n",
    "    cv_results_co2 = cross_validate(\n",
    "        pipeline_co2,\n",
    "        X_co2,\n",
    "        y_co2_log,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    r2_train_mean_co2 = cv_results_co2[\"train_r2\"].mean()\n",
    "    r2_cv_mean_co2 = cv_results_co2[\"test_r2\"].mean()\n",
    "    r2_cv_std_co2 = cv_results_co2[\"test_r2\"].std()\n",
    "\n",
    "    mae_cv_mean_co2 = -cv_results_co2[\"test_mae\"].mean()\n",
    "    rmse_cv_mean_co2 = -cv_results_co2[\"test_rmse\"].mean()\n",
    "\n",
    "    overfit_gap_co2 = r2_train_mean_co2 - r2_cv_mean_co2\n",
    "\n",
    "    print(f\"‚úÖ {model_name}\")\n",
    "    print(f\"   R¬≤ Train : {r2_train_mean_co2:.4f}\")\n",
    "    print(f\"   R¬≤ CV    : {r2_cv_mean_co2:.4f} ¬± {r2_cv_std_co2:.4f}\")\n",
    "    print(f\"   MAE CV   : {mae_cv_mean_co2:.4f}\")\n",
    "    print(f\"   RMSE CV  : {rmse_cv_mean_co2:.4f}\")\n",
    "\n",
    "    if overfit_gap_co2 > 0.15:\n",
    "        print(f\"   ‚ö†Ô∏è Surapprentissage (√©cart = {overfit_gap_co2:.4f})\")\n",
    "    elif overfit_gap_co2 < -0.05:\n",
    "        print(\"   ‚ö†Ô∏è Sous-apprentissage\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Bon √©quilibre (√©cart = {overfit_gap_co2:.4f})\")\n",
    "\n",
    "    results_co2.append(\n",
    "        {\n",
    "            \"Mod√®le\": model_name,\n",
    "            \"R¬≤ CV (mean)\": r2_cv_mean_co2,\n",
    "            \"R¬≤ CV (std)\": r2_cv_std_co2,\n",
    "            \"MAE CV\": mae_cv_mean_co2,\n",
    "            \"RMSE CV\": rmse_cv_mean_co2,\n",
    "            \"R¬≤ Train\": r2_train_mean_co2,\n",
    "            \"Overfit Gap\": overfit_gap_co2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Cross-Validation termin√©e pour TARGET 2 (CO2)\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Comparaison des Mod√®les (TARGET 2 - CO2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Tableau comparatif TARGET 2 (CO2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä TABLEAU R√âCAPITULATIF - TARGET 2 (CO2)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "comparison_df_co2 = pd.DataFrame(results_co2).sort_values(\n",
    "    by=\"R¬≤ CV (mean)\", ascending=False\n",
    ")\n",
    "\n",
    "print(comparison_df_co2.to_string(index=False))\n",
    "\n",
    "best_model_name_co2 = comparison_df_co2.iloc[0][\"Mod√®le\"]\n",
    "best_r2_cv_co2 = comparison_df_co2.iloc[0][\"R¬≤ CV (mean)\"]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üèÜ MEILLEUR MOD√àLE (selon R¬≤ CV) : {best_model_name_co2}\")\n",
    "print(f\"   R¬≤ CV = {best_r2_cv_co2:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Comparaison termin√©e pour TARGET 2 (CO2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîß Optimisation des Hyperparam√®tres - TARGET 2 (CO2)\n",
    "\n",
    "**üéØ Objectif :** Optimiser les hyperparam√®tres du mod√®le champion (LightGBM) identifi√© par Cross-Validation.\n",
    "\n",
    "**Grille adapt√©e √† LightGBM :**\n",
    "\n",
    "- `n_estimators` : Nombre d'arbres\n",
    "- `max_depth` : Profondeur maximale des arbres\n",
    "- `learning_rate` : Taux d'apprentissage (vitesse de convergence)\n",
    "- `num_leaves` : Nombre de feuilles par arbre (sp√©cifique LightGBM)\n",
    "- `min_child_samples` : Nombre minimal d'observations par feuille\n",
    "\n",
    "**üí° LightGBM vs Random Forest :**\n",
    "\n",
    "LightGBM utilise le **boosting** (arbres s√©quentiels qui corrigent les erreurs des pr√©c√©dents), contrairement √† Random Forest qui utilise le **bagging** (arbres ind√©pendants en parall√®le). Les hyperparam√®tres sont donc diff√©rents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : GridSearchCV pour LightGBM (TARGET 2)\n",
    "\n",
    "print(\"üîß OPTIMISATION HYPERPARAM√àTRES - TARGET 2 (CO2)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Mod√®le √† optimiser : {best_model_name_co2}\")\n",
    "print(f\"Performance de base (R¬≤ CV) : {best_r2_cv_co2:.4f}\\n\")\n",
    "\n",
    "# Grille d'hyperparam√®tres pour LightGBM (limit√©e √† ~100 combinaisons)\n",
    "param_grid_co2 = {\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    \"model__max_depth\": [10, 20, 30],\n",
    "    \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"model__num_leaves\": [31, 50],\n",
    "    \"model__min_child_samples\": [20, 50],\n",
    "}\n",
    "\n",
    "# Calcul du nombre de combinaisons\n",
    "n_combinations_co2 = 3 * 3 * 3 * 2 * 2\n",
    "print(f\"üìä Nombre de combinaisons √† tester : {n_combinations_co2}\")\n",
    "print(f\"‚è±Ô∏è Temps estim√© : {n_combinations_co2 * 5 // 60} minutes (environ)\\n\")\n",
    "\n",
    "# Construction du pipeline avec LightGBM\n",
    "pipeline_to_optimize_co2 = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor_co2),\n",
    "        (\"model\", lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# GridSearchCV avec Cross-Validation\n",
    "print(\"üîÑ Lancement de GridSearchCV (peut prendre plusieurs minutes)...\\n\")\n",
    "\n",
    "grid_search_co2 = GridSearchCV(\n",
    "    estimator=pipeline_to_optimize_co2,\n",
    "    param_grid=param_grid_co2,\n",
    "    cv=cv,  # R√©utilise le KFold(5) d√©fini pr√©c√©demment\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "# Entra√Ænement (teste toutes les combinaisons)\n",
    "grid_search_co2.fit(X_co2, y_co2_log)\n",
    "\n",
    "# R√©sultats\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ GridSearchCV termin√© !\")\n",
    "print(\"\\nüèÜ MEILLEURS HYPERPARAM√àTRES TROUV√âS :\")\n",
    "for param, value in grid_search_co2.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(\"\\nüìä PERFORMANCES :\")\n",
    "print(f\"   R¬≤ CV (optimis√©) : {grid_search_co2.best_score_:.4f}\")\n",
    "print(f\"   R¬≤ CV (base)     : {best_r2_cv_co2:.4f}\")\n",
    "\n",
    "# Calcul de la diff√©rence\n",
    "improvement_co2 = grid_search_co2.best_score_ - best_r2_cv_co2\n",
    "print(\n",
    "    f\"\\nüìà Am√©lioration : {improvement_co2:+.4f} ({improvement_co2 / best_r2_cv_co2 * 100:+.2f}%)\"\n",
    ")\n",
    "\n",
    "if improvement_co2 > 0:\n",
    "    print(\"   ‚úÖ GridSearchCV a am√©lior√© les performances !\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è GridSearchCV n'a pas am√©lior√© les performances.\")\n",
    "    print(\"   ‚Üí Les hyperparam√®tres par d√©faut √©taient d√©j√† optimaux.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä D√©cision Finale - TARGET 2 (CO2)\n",
    "\n",
    "**Question :** Quel mod√®le utiliser pour la pr√©diction finale ?\n",
    "\n",
    "Nous allons comparer :\n",
    "\n",
    "1. **Mod√®le de base** : LightGBM avec hyperparam√®tres par d√©faut\n",
    "2. **Mod√®le optimis√©** : LightGBM avec hyperparam√®tres optimis√©s par GridSearchCV\n",
    "\n",
    "Le mod√®le avec le **meilleur R¬≤ CV** sera retenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Comparaison Mod√®le de Base vs Mod√®le Optimis√© (TARGET 2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä COMPARAISON FINALE - TARGET 2 (CO2)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Cr√©ation du DataFrame de comparaison\n",
    "comparison_final_co2 = pd.DataFrame(\n",
    "    {\n",
    "        \"Mod√®le\": [\"LightGBM (Base)\", \"LightGBM (Optimis√©)\"],\n",
    "        \"R¬≤ CV\": [best_r2_cv_co2, grid_search_co2.best_score_],\n",
    "        \"Hyperparam√®tres\": [\"Par d√©faut\", \"GridSearchCV\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tri par R¬≤ CV d√©croissant\n",
    "comparison_final_co2 = comparison_final_co2.sort_values(\n",
    "    \"R¬≤ CV\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(comparison_final_co2.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Identification du meilleur mod√®le FINAL\n",
    "if best_r2_cv_co2 >= grid_search_co2.best_score_:\n",
    "    final_model_name_co2 = \"LightGBM (Base)\"\n",
    "    final_r2_co2 = best_r2_cv_co2\n",
    "    # Reconstruire le pipeline de base\n",
    "    final_pipeline_co2 = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor_co2),\n",
    "            (\n",
    "                \"model\",\n",
    "                lgb.LGBMRegressor(\n",
    "                    n_estimators=100, random_state=42, n_jobs=-1, verbose=-1\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    final_pipeline_co2.fit(X_co2, y_co2_log)\n",
    "    print(\"üèÜ MOD√àLE RETENU : LightGBM avec hyperparam√®tres PAR D√âFAUT\")\n",
    "    print(f\"   R¬≤ CV = {final_r2_co2:.4f}\")\n",
    "    print(\n",
    "        \"\\nüí° Conclusion : Les hyperparam√®tres par d√©faut sont optimaux pour ce dataset.\"\n",
    "    )\n",
    "else:\n",
    "    final_model_name_co2 = \"LightGBM (Optimis√©)\"\n",
    "    final_r2_co2 = grid_search_co2.best_score_\n",
    "    final_pipeline_co2 = grid_search_co2.best_estimator_\n",
    "    print(\"üèÜ MOD√àLE RETENU : LightGBM avec hyperparam√®tres OPTIMIS√âS\")\n",
    "    print(f\"   R¬≤ CV = {final_r2_co2:.4f}\")\n",
    "    print(\"\\nüí° Conclusion : GridSearchCV a am√©lior√© les performances.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance - TARGET 2 (CO2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE : Feature Importance TARGET 2 (CO2)\n",
    "\n",
    "print(\"üìä Feature Importance - TARGET 2 (CO2)\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Utilisation du mod√®le FINAL (base ou optimis√© selon comparaison)\n",
    "print(f\"üîÑ Entra√Ænement de {final_model_name_co2} sur tout le dataset...\")\n",
    "\n",
    "# On r√©entra√Æne le pipeline final sur tout le dataset (si pas d√©j√† fait)\n",
    "if final_model_name_co2 == \"LightGBM (Optimis√©)\":\n",
    "    # Le pipeline est d√©j√† entra√Æn√© depuis grid_search_co2.best_estimator_\n",
    "    pass\n",
    "else:\n",
    "    # On r√©entra√Æne le pipeline de base\n",
    "    final_pipeline_co2.fit(X_co2, y_co2_log)\n",
    "\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©\\n\")\n",
    "\n",
    "# Extraction du mod√®le du pipeline\n",
    "final_model_co2 = final_pipeline_co2.named_steps[\"model\"]\n",
    "\n",
    "if hasattr(final_model_co2, \"feature_importances_\"):\n",
    "    feature_importances_co2 = final_model_co2.feature_importances_\n",
    "\n",
    "    feature_names_co2 = (\n",
    "        numeric_features_co2\n",
    "        + final_pipeline_co2.named_steps[\"preprocessor\"]\n",
    "        .named_transformers_[\"cat\"]\n",
    "        .named_steps[\"onehot\"]\n",
    "        .get_feature_names_out(categorical_features_co2)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    importance_df_co2 = pd.DataFrame(\n",
    "        {\"Feature\": feature_names_co2, \"Importance\": feature_importances_co2}\n",
    "    ).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    importance_df_co2[\"Importance (%)\"] = (\n",
    "        importance_df_co2[\"Importance\"] / importance_df_co2[\"Importance\"].sum() * 100\n",
    "    )\n",
    "\n",
    "    top_15_co2 = importance_df_co2.head(15)\n",
    "\n",
    "    print(\"üîù TOP 15 Features les plus importantes :\\n\")\n",
    "    for idx, row in top_15_co2.iterrows():\n",
    "        print(f\"{row['Feature']:40} : {row['Importance (%)']:5.2f}%\")\n",
    "\n",
    "    top_3_co2 = importance_df_co2.head(3)\n",
    "    top_3_pct_co2 = top_3_co2[\"Importance (%)\"].sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\nüí° Les 3 features les plus importantes repr√©sentent {top_3_pct_co2:.2f}% de l'importance totale\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {best_model_name_co2} ne supporte pas feature_importances_\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Analyse Feature Importance termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üèÅ CONCLUSION FINALE DU PROJET\n",
    "\n",
    "## üìä R√©capitulatif des Deux Targets\n",
    "\n",
    "**Ce projet a permis de construire deux mod√®les de r√©gression supervis√©e performants pour pr√©dire :**\n",
    "1. **La consommation √©nerg√©tique** (`SiteEnergyUse(kBtu)`)\n",
    "2. **Les √©missions de CO2** (`TotalGHGEmissions`)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ R√©sultats Target 1 - Consommation √ânerg√©tique\n",
    "\n",
    "**Meilleur mod√®le :** Random Forest **OPTIMIS√â** (GridSearchCV)\n",
    "\n",
    "**Performances obtenues :**\n",
    "\n",
    "- **R¬≤ CV (optimis√©) : 0.7288** (73% de variance expliqu√©e)\n",
    "- **R¬≤ CV (base) : 0.7159**\n",
    "- **Am√©lioration GridSearchCV : +1.8%** üöÄ\n",
    "- MAE CV : 0.5041\n",
    "- RMSE CV : 0.7027\n",
    "\n",
    "**üîß Optimisation par GridSearchCV :**\n",
    "\n",
    "J'ai appliqu√© GridSearchCV avec Cross-Validation (K=5) pour optimiser les hyperparam√®tres du mod√®le champion Random Forest. GridSearchCV a test√© **144 combinaisons** d'hyperparam√®tres (n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features). Les r√©sultats montrent une am√©lioration de **+1.8%**, confirmant que l'optimisation apporte un gain de performance mesurable.\n",
    "\n",
    "**üí° Pourquoi GridSearchCV fonctionne avec Pipeline + CV ?**\n",
    "\n",
    "Contrairement √† l'approche Train/Test unique, l'utilisation de GridSearchCV avec Pipeline + Cross-Validation permet une optimisation robuste qui am√©liore r√©ellement les performances, car :\n",
    "\n",
    "- Chaque combinaison est √©valu√©e sur **5 folds diff√©rents**\n",
    "- Le Pipeline emp√™che le data leakage (preprocessing uniquement sur train fold)\n",
    "- Pas de suroptimisation sur un seul split\n",
    "\n",
    "**Variables les plus importantes** (Feature Importance du mod√®le optimis√©) :\n",
    "\n",
    "1. `PropertyGFABuilding(s)` - Surface des b√¢timents **(16.78%)**\n",
    "2. `PropertyGFATotal` - Surface totale de la propri√©t√© **(13.71%)**\n",
    "3. `LargestPropertyUseTypeGFA` - Surface du type d'usage dominant **(9.31%)**\n",
    "4. `SurfaceGasInteraction` - Feature d'interaction cr√©√©e (Surface √ó Gaz naturel) **(9.05%)**\n",
    "\n",
    "üí° Les 3 features les plus importantes repr√©sentent **39.80%** de l'importance totale\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ R√©sultats Target 2 - √âmissions de CO2\n",
    "\n",
    "**Meilleur mod√®le :** LightGBM **OPTIMIS√â** (GridSearchCV)\n",
    "\n",
    "**Performances obtenues :**\n",
    "\n",
    "- **R¬≤ CV (optimis√©) : 0.9218** (92% de variance expliqu√©e) üéØ **Performance exceptionnelle !**\n",
    "- **R¬≤ CV (base) : 0.9214**\n",
    "- **Am√©lioration GridSearchCV : +0.05%** ‚úÖ\n",
    "- MAE CV : 0.2829\n",
    "- RMSE CV : 0.4042\n",
    "\n",
    "**üîß Optimisation par GridSearchCV :**\n",
    "\n",
    "J'ai appliqu√© GridSearchCV pour optimiser les hyperparam√®tres de LightGBM. GridSearchCV a test√© **108 combinaisons** d'hyperparam√®tres sp√©cifiques au boosting (n_estimators, max_depth, learning_rate, num_leaves, min_child_samples). Bien que l'am√©lioration soit l√©g√®re (+0.05%), elle confirme que les hyperparam√®tres optimis√©s sont adapt√©s au dataset.\n",
    "\n",
    "**Variables les plus importantes** :\n",
    "\n",
    "1. **`SiteEnergyUse(kBtu)`** - Consommation √©nerg√©tique totale **(16.97%)**\n",
    "2. **`EnergyPerSurface`** - Intensit√© √©nerg√©tique (kBtu/ft¬≤) ‚Üê Feature cr√©√©e ! **(12.05%)**\n",
    "3. **`DistanceToCenter`** - Distance au centre de Seattle **(10.15%)**\n",
    "4. `BuildingAge` - √Çge du b√¢timent **(9.52%)**\n",
    "5. `LargestPropertyUseTypeGFA` - Surface du type d'usage dominant **(6.78%)**\n",
    "6. **`SurfaceGasInteraction`** - Interaction Surface √ó Gaz naturel ‚Üê Feature cr√©√©e ! **(5.79%)**\n",
    "\n",
    "üí° Les 3 features les plus importantes repr√©sentent **39.18%** de l'importance totale\n",
    "\n",
    "**üí° Insight majeur :** `SiteEnergyUse` domine (#1 avec 17%), confirmant que la consommation √©nerg√©tique est le pr√©dicteur principal des √©missions CO2. Les features cr√©√©es (`EnergyPerSurface` #2 et `SurfaceGasInteraction` #6) restent tr√®s importantes.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ M√©thodologie Compl√®te Appliqu√©e\n",
    "\n",
    "**‚úÖ Pipeline sklearn** : Encapsulation preprocessing + mod√®le (√©vite data leakage)  \n",
    "**‚úÖ ColumnTransformer** : Traitement s√©par√© numeric (imputation m√©diane + scaling) et categorical (imputation mode + one-hot)  \n",
    "**‚úÖ Cross-Validation K-Fold (K=5)** : 5 splits train/validation ind√©pendants ‚Üí moyenne robuste  \n",
    "**‚úÖ Comparaison de 4 algorithmes** : LinearRegression, Random Forest, SVR, LightGBM  \n",
    "**‚úÖ GridSearchCV** : Optimisation des hyperparam√®tres du champion (144 combinaisons Energy, 108 CO2)  \n",
    "**‚úÖ Feature Engineering** : 10 nouvelles features cr√©√©es (interactions, ratios, encodages)  \n",
    "**‚úÖ Data Leakage Prevention** : Exclusion rigoureuse des targets crois√©es + Pipeline  \n",
    "**‚úÖ Transformation Log** : Normalisation des distributions asym√©triques  \n",
    "**‚úÖ Reproductibilit√©** : random_state=42 partout, shuffle=True dans KFold\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Enseignements Cl√©s\n",
    "\n",
    "1. **Les features d'interaction sont CRUCIALES** : `EnergyPerSurface` et `SurfaceGasInteraction` dominent le TOP pour CO2\n",
    "   - Target 1 (√ânergie) : Features structurelles (surfaces) dominantes\n",
    "   - Target 2 (CO2) : Feature √©nerg√©tique + interactions dominent ‚Üí SiteEnergyUse est le pr√©dicteur #1\n",
    "2. **GridSearchCV + Pipeline + CV = Optimisation robuste** :\n",
    "   - ‚ùå GridSearchCV sur Train/Test simple : Risque de suroptimisation\n",
    "   - ‚úÖ GridSearchCV avec Pipeline + CV : Optimisation robuste, chaque combinaison √©valu√©e sur 5 folds\n",
    "   - R√©sultat : +1.8% pour Energy, +0.05% pour CO2\n",
    "3. **Cross-Validation >> Train/Test simple** :\n",
    "   - ‚ùå Train/Test : 1 seul split ‚Üí d√©pend du random_state, y_train_pred √©value sur donn√©es vues\n",
    "   - ‚úÖ CV K-Fold : 5 splits ‚Üí estimation robuste, toujours √©value sur donn√©es non vues\n",
    "4. **Pipeline sklearn √©vite le data leakage** : Preprocessing (scaling, encoding) appliqu√© UNIQUEMENT sur train fold √† chaque it√©ration\n",
    "5. **La transformation log est cruciale** pour g√©rer l'asym√©trie des distributions\n",
    "6. **`SiteEnergyUse` est le pr√©dicteur #1 pour CO2** : 17% d'importance, confirme lien direct √©nergie ‚Üí √©missions\n",
    "7. **ThirdLargestPropertyUseType\\* conserv√©es** : Malgr√© 50% NaN, contribuent √† la pr√©diction (conseil mentor valid√©)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä √âvaluation de l'Overfitting\n",
    "\n",
    "**Qu'est-ce que l'Overfit Gap ?**  \n",
    "√âcart entre R¬≤ moyen sur les donn√©es d'entra√Ænement (Train) et R¬≤ moyen sur validation crois√©e (CV).\n",
    "\n",
    "**Interpr√©tation :**\n",
    "\n",
    "- **Gap = R¬≤ Train - R¬≤ CV**\n",
    "- Plus le gap est faible, meilleur est le compromis biais-variance\n",
    "\n",
    "**Seuils d'interpr√©tation (r√®gle g√©n√©rale) :**\n",
    "\n",
    "- **0-0.05** : Excellent - Mod√®le bien r√©gularis√©\n",
    "- **0.05-0.15** : Tr√®s bon - Compromis id√©al biais-variance\n",
    "- **0.15-0.25** : Acceptable - Overfitting mod√©r√©\n",
    "- **>0.25** : Probl√©matique - R√©gularisation n√©cessaire\n",
    "\n",
    "**üí° Note importante :** Un gap de 0 est **impossible** et **ind√©sirable** (underfitting). Les mod√®les complexes ont naturellement un petit gap.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Applications Business\n",
    "\n",
    "**Ces mod√®les permettent de :**\n",
    "\n",
    "- Pr√©dire la consommation √©nerg√©tique (R¬≤ = 0.73) et les √©missions CO2 (R¬≤ = 0.92) de nouveaux b√¢timents **avant construction**\n",
    "- Prioriser les actions d'efficacit√© √©nerg√©tique selon les features importantes :\n",
    "  - **√ânergie** : Agir sur la surface des b√¢timents, le type d'usage\n",
    "  - **CO2** : R√©duire la consommation √©nerg√©tique (pr√©dicteur #1), optimiser l'intensit√© √©nerg√©tique\n",
    "- Estimer l'impact de r√©novations structurelles (changement de surface, conversion source √©nergie)\n",
    "- Identifier les b√¢timents √† fort potentiel d'am√©lioration √©nerg√©tique\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ TABLEAU R√âCAPITULATIF FINAL\n",
    "\n",
    "| Target      | Meilleur Mod√®le | R¬≤ CV (Base) | R¬≤ CV (Optimis√©) | Am√©lioration | Algorithme |\n",
    "| ----------- | --------------- | ------------ | ---------------- | ------------ | ---------- |\n",
    "| **√ânergie** | Random Forest   | 0.7159       | **0.7288**       | **+1.8%**    | Bagging    |\n",
    "| **CO2**     | LightGBM        | 0.9214       | **0.9218**       | **+0.05%**   | Boosting   |\n",
    "\n",
    "**üí° Conclusion :** GridSearchCV avec Pipeline + Cross-Validation a permis d'optimiser les deux mod√®les, avec une am√©lioration significative pour Energy (+1.8%) et une confirmation des hyperparam√®tres optimaux pour CO2 (+0.05%).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
